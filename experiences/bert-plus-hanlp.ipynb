{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c27818-9b42-4e34-b8cc-c27f435d017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import hanlp\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd6b0cd-389d-42e1-bc2b-5f15d1e2e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hyperparameters\n",
    "EPOCH_NUMBERS = 20\n",
    "BATCH_SIZE = 16\n",
    "WIQA_TRAIN = '../datasets/wiqa-dataset-v2-october-2019/train.jsonl'\n",
    "WIQA_TEST = '../datasets/wiqa-dataset-v2-october-2019/test.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19843d35-9940-49d5-9696-b1fc9935d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d7ff20-f205-41fb-8510-360ff47c916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(WIQA_TRAIN, 'r') as json_file:\n",
    "    train_data = [json.loads(line) for line in json_file]\n",
    "\n",
    "with open(WIQA_TEST, 'r') as json_file:\n",
    "    test_data = [json.loads(line) for line in json_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e5255e-a7f0-4577-8b58-82614b72bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer and model\n",
    "HanLP = hanlp.load(hanlp.pretrained.mtl.UD_ONTONOTES_TOK_POS_LEM_FEA_NER_SRL_DEP_SDP_CON_XLMR_BASE)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels = 3, # The number of output labels. Here, it's 3: more, less, no effect.\n",
    "    output_attentions = False, \n",
    "    output_hidden_states = False, \n",
    ")\n",
    "\n",
    "# Extract context (para_steps), questions (stem), and labels (answer_label)\n",
    "contexts=[]\n",
    "questions = []\n",
    "labels = []\n",
    "\n",
    "for item in train_data:\n",
    "    para = \" \".join([p.strip() for p in item[\"question\"][\"para_steps\"] if len(p) > 0])\n",
    "    contexts.append(para)\n",
    "    questions.append(item['question']['stem'].strip())\n",
    "    labels.append(item['question']['answer_label'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc39241-ae22-43f8-b867-60c0ea134549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29808/29808 [00:11<00:00,  8.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create separate lists for each answer option\n",
    "options = [\"more\", \"less\", \"no_effect\"]\n",
    "labels_option = [options.index(label) for label in labels]\n",
    "\n",
    "# Tokenization Process with Constituency Parsing\n",
    "def encode_example(context, question, option):\n",
    "    hanlp_parser = HanLP([question])\n",
    "    parser_question = hanlp_parser['con']\n",
    "    \n",
    "    # Join together the context, question, and answer option using BERT's special tokens\n",
    "    encoded = tokenizer.encode_plus(f\"[CLS] {context} [SEP] {parser_question} [SEP] {option}\", truncation=True, padding='max_length', max_length=512)\n",
    "    return encoded[\"input_ids\"], encoded[\"attention_mask\"]\n",
    "\n",
    "train_encodings = []\n",
    "for i in tqdm(range(len(contexts))):\n",
    "    context = contexts[i]\n",
    "    question = questions[i]\n",
    "    for option in options:\n",
    "        encoding = encode_example(context, question, option)\n",
    "        train_encodings.append(encoding)\n",
    "\n",
    "train_labels_option = []\n",
    "for label in labels_option:\n",
    "    for _ in options:\n",
    "        train_labels_option.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86e6b93e-2bc0-448f-a6c3-a93bcaf48cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch data types\n",
    "train_dataset = TensorDataset(torch.tensor([item[0] for item in train_encodings]), torch.tensor([item[1] for item in train_encodings]), torch.tensor(train_labels_option))\n",
    "\n",
    "label_dict = {\"more\": 0, \"less\": 1, \"no_effect\": 2}\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc2c1b56-8a1f-4572-91e6-ddcfaf96b8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6585332d-1fa8-49b0-9a96-04cc71f76184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 1: 1.102248163599717\n",
      "Average loss in epoch 2: 1.0745071862873279\n",
      "Average loss in epoch 3: 1.022660704035508\n",
      "Average loss in epoch 4: 0.9097064670763517\n",
      "Average loss in epoch 5: 0.9007854367557325\n",
      "Average loss in epoch 6: 0.7459529214783719\n",
      "Average loss in epoch 7: 0.6374646142909401\n",
      "Average loss in epoch 8: 0.5237770519758526\n",
      "Average loss in epoch 9: 0.3616815044691688\n",
      "Average loss in epoch 10: 0.2635155759359661\n",
      "Average loss in epoch 11: 0.24531049712708122\n",
      "Average loss in epoch 12: 0.15274907805417715\n",
      "Average loss in epoch 13: 0.12143663297358312\n",
      "Average loss in epoch 14: 0.09793458271183465\n",
      "Average loss in epoch 15: 0.0798404565767238\n",
      "Average loss in epoch 16: 0.09473790316597412\n",
      "Average loss in epoch 17: 0.04080364059068655\n",
      "Average loss in epoch 18: 0.04383237743260045\n",
      "Average loss in epoch 19: 0.03539923622616028\n",
      "Average loss in epoch 20: 0.031377225231967475\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Adjust model forward pass\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for _,data in enumerate(train_loader, 0):\n",
    "        ids = data[0].to(device, dtype = torch.long)\n",
    "        mask = data[1].to(device, dtype = torch.long)\n",
    "        targets = data[2].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Compute the cross-entropy loss\n",
    "        loss_function = torch.nn.CrossEntropyLoss()\n",
    "        loss = loss_function(logits.view(-1, 3), targets.view(-1))\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    print(f'Average loss in epoch {epoch}: {total_loss/len(train_loader)}')\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(1, EPOCH_NUMBERS+1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdadabd6-c5e0-4839-b608-52f918cc3001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(para_steps, question):\n",
    "    # Join the steps into a single text\n",
    "    context = ' '.join(para_steps)\n",
    "    \n",
    "    # Prepare the inputs for the model\n",
    "    inputs = tokenizer(context, question, return_tensors='pt', max_length=512, padding='max_length', truncation=True)\n",
    "\n",
    "    # Move the inputs to the device\n",
    "    inputs = {name: tensor.to(device) for name, tensor in inputs.items()}\n",
    "    \n",
    "    # Get the model's predictions\n",
    "    output = model(**inputs)\n",
    "\n",
    "    _, prediction = torch.max(output.logits, dim=1)\n",
    "\n",
    "    # Convert numerical prediction back to original label\n",
    "    reverse_label_dict = {v: k for k, v in label_dict.items()}\n",
    "    return reverse_label_dict[prediction.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b455843a-573c-480b-a162-16d24da9d281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3003/3003 [00:34<00:00, 86.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# List to store the true and predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Map text to corresponding label\n",
    "label_dict = {\"more\": 0, \"less\": 1, \"no_effect\": 2}\n",
    "\n",
    "\n",
    "for entry in tqdm(test_data):\n",
    "    question = entry['question']['stem']\n",
    "    para_steps = entry['question']['para_steps']\n",
    "    true_answer = entry['question']['answer_label']\n",
    "    predicted_answer = predict(para_steps, question)\n",
    "    \n",
    "    y_true.append(true_answer)\n",
    "    y_pred.append(predicted_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40b83aeb-482e-45c0-9d57-963ccb18b641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7325377661080531\n"
     ]
    }
   ],
   "source": [
    "# Calculate the F1 score\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f'F1 score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea8e83-478f-486d-aa81-87a0e45609b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fulgid",
   "language": "python",
   "name": "fulgid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
